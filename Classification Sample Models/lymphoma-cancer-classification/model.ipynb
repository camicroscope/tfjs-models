{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lymphoma_cancer_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc9UCDPps2SI",
        "colab_type": "text"
      },
      "source": [
        "## Google Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL_GqMswqQ4h",
        "colab_type": "code",
        "outputId": "4655e3a8-3ff4-4c8b-e9de-c41f4e7c6712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at ./gdrive; to attempt to forcibly remount, call drive.mount(\"./gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vO4fMdxQna6",
        "colab_type": "code",
        "outputId": "e77c6255-cd9f-4f73-95b0-16813855f8d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd ./gdrive/\"My Drive\"/model3bmi "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/model3bmi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJGXIK8AEMzY",
        "colab_type": "text"
      },
      "source": [
        "### Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Weu7RsyiQ-ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Credits: ICIAR2018 by ImagingLabs\n",
        "class PatchExtractor:\n",
        "    def __init__(self, img, patch_size, stride):\n",
        "        '''\n",
        "        :param img: :py:class:`~PIL.Image.Image`\n",
        "        :param patch_size: integer, size of the patch\n",
        "        :param stride: integer, size of the stride\n",
        "        '''\n",
        "        self.img = img\n",
        "        self.size = patch_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def extract_patches(self):\n",
        "        \"\"\"\n",
        "        extracts all patches from an image\n",
        "        :returns: A list of :py:class:`~PIL.Image.Image` objects.\n",
        "        \"\"\"\n",
        "        wp, hp = self.shape()\n",
        "        return [self.extract_patch((w, h)) for h in range(hp) for w in range(wp)]\n",
        "\n",
        "    def extract_patch(self, patch):\n",
        "        \"\"\"\n",
        "        extracts a patch from an input image\n",
        "        :param patch: a tuple\n",
        "        :rtype: :py:class:`~PIL.Image.Image`\n",
        "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
        "        \"\"\"\n",
        "        return self.img.crop((\n",
        "            patch[0] * self.stride,  # left\n",
        "            patch[1] * self.stride,  # up\n",
        "            patch[0] * self.stride + self.size,  # right\n",
        "            patch[1] * self.stride + self.size  # down\n",
        "        ))\n",
        "\n",
        "    def shape(self):\n",
        "        wp = int((self.img.width - self.size) / self.stride + 1)\n",
        "        hp = int((self.img.height - self.size) / self.stride + 1)\n",
        "        return wp, hp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOEfGa4OTrm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir new_train/MCL new_train/FL new_train/CLL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccYl8m-rTHKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "LABELS = ['CLL', 'FL', 'MCL']\n",
        "PATCH_SIZE = 256\n",
        "STRIDE = 256\n",
        "\n",
        "# The folder containing training data\n",
        "train_folder = './train'\n",
        "labels = {name: LABELS[index] for index in range(len(LABELS)) for name in glob.glob(train_folder + '/' + LABELS[index] + '/*.tif')}\n",
        "\n",
        "for key, value in labels.items():\n",
        "  try:\n",
        "    with Image.open(key) as img:\n",
        "      # the patch-size and stride is according to the paper\n",
        "      extractor = PatchExtractor(img=img, patch_size=PATCH_SIZE, stride=STRIDE)\n",
        "      patches = extractor.extract_patches()\n",
        "      count = 0\n",
        "      for p in patches:\n",
        "        count += 1\n",
        "        p.save('./new_train/' + value + '/' + str(count) + '_' + key.split('/')[-1])\n",
        "  except Exception as error:\n",
        "    print('error with', key, error)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y4j-cShYT6Mz"
      },
      "source": [
        "## Inception Recurrent Convolutional Neural Network (IRCNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7PLwcGm5jHz",
        "colab_type": "code",
        "outputId": "ae0d9538-3d52-4a4a-efd2-f66d02554054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sys\n",
        "import warnings\n",
        "# Keras Core\n",
        "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers import Add\n",
        "from keras import regularizers\n",
        "from keras import initializers\n",
        "from keras.models import Model\n",
        "\n",
        "# Backend\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdmOO-QX5o3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolution 2D with batch norm\n",
        "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
        "            padding='same', strides=(1, 1), use_bias=False):\n",
        "  \"\"\"\n",
        "  Utility function to apply conv + BN. \n",
        "  (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
        "  \"\"\"\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "    channel_axis = -1\n",
        "  x = Convolution2D(nb_filter, (num_row, num_col),\n",
        "                    strides=strides,\n",
        "                    padding=padding,\n",
        "                    use_bias=use_bias,\n",
        "                    kernel_regularizer=regularizers.l2(0.00004),\n",
        "                    kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
        "  x = Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "# Recurrent convolutional layer\n",
        "def RCL(input, kernel_size, filedepth):\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "    channel_axis = -1\n",
        "\n",
        "  conv1 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(0.00004),\n",
        "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(input)\n",
        "\n",
        "  stack2 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(conv1)\n",
        "  stack2 = Activation('relu')(stack2)\n",
        "\n",
        "  RCL = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same', \n",
        "                 kernel_regularizer=regularizers.l2(0.00004),\n",
        "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))\n",
        "\n",
        "  conv2 = RCL(stack2)\n",
        "  stack3 = Add()([conv1, conv2])\n",
        "  stack4 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack3)\n",
        "  stack4 = Activation('relu')(stack4)\n",
        "\n",
        "\n",
        "  conv3 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
        "                 weights=RCL.get_weights(),\n",
        "                 kernel_regularizer=regularizers.l2(0.00004),\n",
        "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(stack4)\n",
        "  stack5 = Add()([conv1, conv3])\n",
        "  stack6 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack5)\n",
        "  stack6 = Activation('relu')(stack6)\n",
        "\n",
        "\n",
        "  conv4 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
        "                 weights=RCL.get_weights(),\n",
        "                 kernel_regularizer=regularizers.l2(0.00004),\n",
        "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(stack6)\n",
        "  stack7 = Add()([conv1, conv4])\n",
        "  stack8 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack7)\n",
        "  stack8 = Activation('relu')(stack8)\n",
        "\n",
        "  return stack8\n",
        "\n",
        "\n",
        "def IRCNN_block(input):\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "    channel_axis = -1\n",
        "\n",
        "  branch_0 = RCL(input, (1, 1), 64)\n",
        "\n",
        "  branch_1 = RCL(input, (3, 3), 128)\n",
        "\n",
        "  branch_2 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "  branch_2 = RCL(branch_2, (1, 1), 64)\n",
        "\n",
        "  x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "  return x\n",
        "\n",
        "\n",
        "def IRCNN_base(input):\n",
        "\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "#     inputShape = (3, 256, 256)\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "#     inputShape = (256, 256, 3)\n",
        "    channel_axis = -1\n",
        "\n",
        "  # Input Shape is 3 x 256 x 256\n",
        "  net = Convolution2D(32, (3, 3), strides=(2,2), padding='valid')(input)\n",
        "  net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
        "  net = conv2d_bn(net, 64, 3, 3)\n",
        "\n",
        "  net = IRCNN_block(input)\n",
        "                 \n",
        "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "  net = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "  net = Dropout(0.5)(net)\n",
        "\n",
        "  net = IRCNN_block(input)\n",
        "                 \n",
        "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "  net = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "  net = Dropout(0.5)(net)\n",
        "                 \n",
        "  net = IRCNN_block(input)\n",
        "                 \n",
        "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "  net = GlobalAveragePooling2D()(net)\n",
        "  net = Dropout(0.5)(net)\n",
        "  \n",
        "  \n",
        "  return net\n",
        "                 \n",
        "\t\t\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHqGqiMIoGlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "  inputs = Input(shape = (3, 256, 256))\n",
        "else:\n",
        "  inputs = Input(shape = (256, 256, 3))\n",
        "\n",
        "x = Convolution2D(32, (3, 3), strides=(2,2), padding='valid')(inputs)\n",
        "x = IRCNN_base(x)\n",
        "x = Dense(units=3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, x, name='IRCNN')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYHzanvs8N0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fc655dea-8a77-4df1-de18-14ead9b66048",
        "id": "nUSWmOqfp4Yn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "aug = ImageDataGenerator(rotation_range=45,\n",
        "                         fill_mode='wrap',\n",
        "                         samplewise_center=True,\n",
        "                         samplewise_std_normalization=True,\n",
        "                         horizontal_flip=True, \n",
        "                         vertical_flip=True, \n",
        "                         validation_split=0.15)\n",
        "bs = 16\n",
        "train_path = './train'\n",
        "\n",
        "train_generator = aug.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=bs,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = aug.flow_from_directory(\n",
        "    train_path, # same directory as training data\n",
        "    target_size=(256, 256),\n",
        "    batch_size=bs,\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6358 images belonging to 3 classes.\n",
            "Found 1122 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XT2zm3q7p4Yv",
        "colab": {}
      },
      "source": [
        "train_step=train_generator.n//train_generator.batch_size\n",
        "valid_step=validation_generator.n//validation_generator.batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T8j-sPf8p4Yx",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "from keras import callbacks\n",
        "import math\n",
        "\n",
        "# adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "sgd = optimizers.SGD(lr=0.02)\n",
        "\n",
        "filepath=\"./models/weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "\n",
        "mcp = callbacks.ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [mcp]\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bu95wKXcp4Y3",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_step,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=valid_step,\n",
        "    epochs=30,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1)\n",
        "\n",
        "# make lr=0.001 after 20 epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rijstjXinbJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
