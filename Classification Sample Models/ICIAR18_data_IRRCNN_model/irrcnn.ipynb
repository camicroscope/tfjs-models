{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits: ICIAR2018 by ImagingLabs\n",
    "class PatchExtractor:\n",
    "    def __init__(self, img, patch_size, stride):\n",
    "        '''\n",
    "        :param img: :py:class:`~PIL.Image.Image`\n",
    "        :param patch_size: integer, size of the patch\n",
    "        :param stride: integer, size of the stride\n",
    "        '''\n",
    "        self.img = img\n",
    "        self.size = patch_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def extract_patches(self):\n",
    "        \"\"\"\n",
    "        extracts all patches from an image\n",
    "        :returns: A list of :py:class:`~PIL.Image.Image` objects.\n",
    "        \"\"\"\n",
    "        wp, hp = self.shape()\n",
    "        return [self.extract_patch((w, h)) for h in range(hp) for w in range(wp)]\n",
    "\n",
    "    def extract_patch(self, patch):\n",
    "        \"\"\"\n",
    "        extracts a patch from an input image\n",
    "        :param patch: a tuple\n",
    "        :rtype: :py:class:`~PIL.Image.Image`\n",
    "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
    "        \"\"\"\n",
    "        return self.img.crop((\n",
    "            patch[0] * self.stride,  # left\n",
    "            patch[1] * self.stride,  # up\n",
    "            patch[0] * self.stride + self.size,  # right\n",
    "            patch[1] * self.stride + self.size  # down\n",
    "        ))\n",
    "\n",
    "    def shape(self):\n",
    "        wp = int((self.img.width - self.size) / self.stride + 1)\n",
    "        hp = int((self.img.height - self.size) / self.stride + 1)\n",
    "        return wp, hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "LABELS = ['Normal', 'Benign', 'InSitu', 'Invasive']\n",
    "IMAGE_SIZE = (2048, 1536)\n",
    "PATCH_SIZE = 128\n",
    "\n",
    "train_folder = './Photos' #this is the folder containing the mages after extracting the dataset\n",
    "labels = {name: LABELS[index] for index in range(len(LABELS)) for name in glob.glob(train_folder + '/' + LABELS[index] + '/*.tif')}\n",
    "count = 0\n",
    "for key, value in labels.items():\n",
    "\n",
    "  try:\n",
    "    with Image.open(key) as img:\n",
    "      # the patch-size and stride is according to the paper\n",
    "      extractor = PatchExtractor(img=img, patch_size=PATCH_SIZE, stride=128)\n",
    "      patches = extractor.extract_patches()\n",
    "      \n",
    "      for p in patches:\n",
    "        count += 1\n",
    "        if(count%5==0):\n",
    "            p.save('./test/' + value + '/' + str(count) + '_' +value+'.tif')\n",
    "        else:\n",
    "            p.save('./train/' + value + '/' + str(count) + '_' +value+'.tif')\n",
    "  except Exception as error:\n",
    "    print('error with', key, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train/'\n",
    "test_path = './test'\n",
    "bs=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12592 images belonging to 4 classes.\n",
      "Found 2220 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=0, brightness_range=(1, 1), horizontal_flip=False, vertical_flip=False, validation_split=0.15)\n",
    "\n",
    "train_generator = aug.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=bs,\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = aug.flow_from_directory(\n",
    "    train_path, # same directory as training data\n",
    "    target_size=(128,128),\n",
    "    batch_size=bs,\n",
    "    subset='validation') # set as validation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "         test_path,\n",
    "         target_size=(128,128),\n",
    "         batch_size=bs,\n",
    "         class_mode='categorical', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Sys\n",
    "import warnings\n",
    "# Keras Core\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Add\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.models import Model\n",
    "\n",
    "# Backend\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the code taken from https://github.com/camicroscope/tfjs-models/tree/master/Classification%20Sample%20Models/lymphoma-cancer-classification\n",
    "# changes made in the model architecture using the papaer https://arxiv.org/abs/1811.04241\n",
    "# Convolution 2D with batch norm\n",
    "\n",
    "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
    "            padding='same', strides=(1, 1), use_bias=False):\n",
    "  \"\"\"\n",
    "  Utility function to apply conv + BN. \n",
    "  (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
    "  \"\"\"\n",
    "  if K.image_data_format() == 'channels_first':\n",
    "    channel_axis = 1\n",
    "  else:\n",
    "    channel_axis = -1\n",
    "  x = Convolution2D(nb_filter, (num_row, num_col),\n",
    "                    strides=strides,\n",
    "                    padding=padding,\n",
    "                    use_bias=use_bias,\n",
    "                    kernel_regularizer=regularizers.l2(0.00004),\n",
    "                    kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
    "  x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
    "  x = Activation('relu')(x)\n",
    "  return x\n",
    "\n",
    "# Recurrent convolutional layer\n",
    "def RCL(input, kernel_size, filedepth):\n",
    "  if K.image_data_format() == 'channels_first':\n",
    "    channel_axis = 1\n",
    "  else:\n",
    "    channel_axis = -1\n",
    "\n",
    "  conv1 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(0.00004),\n",
    "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(input)\n",
    "\n",
    "  stack2 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(conv1)\n",
    "  stack2 = Activation('relu')(stack2)\n",
    "\n",
    "  RCL = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same', \n",
    "                 kernel_regularizer=regularizers.l2(0.00004),\n",
    "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))\n",
    "\n",
    "  conv2 = RCL(stack2)\n",
    "  stack3 = Add()([conv1, conv2])\n",
    "  stack4 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack3)\n",
    "  stack4 = Activation('relu')(stack4)\n",
    "\n",
    "\n",
    "  conv3 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                 weights=RCL.get_weights(),\n",
    "                 kernel_regularizer=regularizers.l2(0.00004),\n",
    "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(stack4)\n",
    "  stack5 = Add()([conv1, conv3])\n",
    "  stack6 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack5)\n",
    "  stack6 = Activation('relu')(stack6)\n",
    "\n",
    "\n",
    "  conv4 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                 weights=RCL.get_weights(),\n",
    "                 kernel_regularizer=regularizers.l2(0.00004),\n",
    "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(stack6)\n",
    "  stack7 = Add()([conv1, conv4])\n",
    "  stack8 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack7)\n",
    "  stack8 = Activation('relu')(stack8)\n",
    "\n",
    "  return stack8\n",
    "\n",
    "\n",
    "\n",
    "def IRRCNN_base(input):\n",
    "\n",
    "  if K.image_data_format() == 'channels_first':\n",
    "#     inputShape = (3, 128, 128)\n",
    "    channel_axis = 1\n",
    "  else:\n",
    "#     inputShape = (128, 128, 3)\n",
    "    channel_axis = -1\n",
    "\n",
    "  # Input Shape is 3 x 128 x 128\n",
    "  net = Convolution2D(32, (3, 3), strides=(2,2), padding='valid')(input)\n",
    "  net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
    "  net = conv2d_bn(net, 64, 3, 3)\n",
    "\n",
    "  net = IRRCNN_block(input)\n",
    "                 \n",
    "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "  net = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "  net = Dropout(0.5)(net)\n",
    "\n",
    "  net = IRRCNN_block(input)\n",
    "                 \n",
    "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "  net = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "  net = Dropout(0.5)(net)\n",
    "                 \n",
    "  net = IRRCNN_block(input)\n",
    "\n",
    "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "  net = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "  net = Dropout(0.5)(net)\n",
    "                 \n",
    "  net = IRRCNN_block(input)\n",
    "                 \n",
    "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "  net = GlobalAveragePooling2D()(net)\n",
    "  net = Dropout(0.5)(net)\n",
    "  return net\n",
    "\n",
    "def IRCNN_block(input):\n",
    "  if K.image_data_format() == 'channels_first':\n",
    "    channel_axis = 1\n",
    "  else:\n",
    "    channel_axis = -1\n",
    "\n",
    "  branch_0 = RCL(input, (1, 1), 64)\n",
    "\n",
    "  branch_1 = RCL(input, (3, 3), 128)\n",
    "\n",
    "  branch_2 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "  branch_2 = RCL(branch_2, (1, 1), 64)\n",
    "\n",
    "  x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "  return x\n",
    "\n",
    "def IRRCNN_block(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    net= IRCNN_block(input)\n",
    "    net1 = Convolution2D(256, (1, 1), padding='valid')(input)\n",
    "    net = Add()([net, net1])\n",
    "\n",
    "    return net\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "  inputs = Input(shape = (3, 128, 128))\n",
    "else:\n",
    "  inputs = Input(shape = (128, 128, 3))\n",
    "x = Convolution2D(32, (3, 3), strides=(2,2), padding='valid')(inputs)\n",
    "x = IRRCNN_base(x)\n",
    "x = Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs, x, name='IRRCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step=train_generator.n//train_generator.batch_size\n",
    "valid_step=validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "import math\n",
    "\n",
    "# adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "filepath=\"./models/weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "mcp = callbacks.ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [mcp]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_step,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=valid_step,\n",
    "        epochs=50,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
